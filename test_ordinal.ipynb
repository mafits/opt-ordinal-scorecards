{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656d72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scorecard import Scorecard\n",
    "import time\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93593078",
   "metadata": {},
   "source": [
    "## aesthetic evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_data = pd.read_csv('datasets/aesthetic_evaluation_data.csv')\n",
    "aesthetic_evaluation_objective = aesthetic_evaluation_data['Objective Evaluation']\n",
    "aesthetic_evaluation_data = aesthetic_evaluation_data.drop(columns=['Image Filename','Author','Objective Evaluation', 'sX2L Value','sX2a Value','sX2b Value','sX2Lab Value','sEMDL Value','sEMDa Value','sEMDb Value','sEMDLab Value'])\n",
    "aesthetic_evaluation_X = aesthetic_evaluation_data.drop(columns='Subjective Evaluation')\n",
    "aesthetic_evaluation_y = aesthetic_evaluation_data['Subjective Evaluation']\n",
    "\n",
    "aesthetic_evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69717b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaded3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.hist()\n",
    "plt.xlabel('Subjective Evaluation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Subjective Evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d52174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of 'objective evaluation' (relative to the target, 'subjective evaluation')\n",
    "acc = accuracy_score(aesthetic_evaluation_y, aesthetic_evaluation_objective)\n",
    "print(f'Accuracy of objective evaluation: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d89ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = aesthetic_evaluation_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'Categorical columns: {categorical_columns}')\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    aesthetic_evaluation_X[col] = aesthetic_evaluation_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {aesthetic_evaluation_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c672465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: 'Poor', 1: 'Fair', 2: 'Good', 3: 'Excellent'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd35a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "caim_1ook_ml_model, caim_1ook_ml_weights = scorecard.fit(aesthetic_evaluation_X, aesthetic_evaluation_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                mapping=mapping)\n",
    "\n",
    "#scorecard.cross_val_score()\n",
    "mse, caim_accuracy, auc = scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc96118",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "scorecard.fit(aesthetic_evaluation_X, aesthetic_evaluation_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                mapping=mapping,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "\n",
    "_, infbins_accuracy, _ = scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80314ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard.plot_accuracy_vs_sparsity(caim_accuracy, num_nonzero_weights, infbins_accuracy, scorecard.nonzero_weights.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "scorecard.fit(aesthetic_evaluation_X, aesthetic_evaluation_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING',\n",
    "                model_method='ML', \n",
    "                use_sbc=True,\n",
    "                mapping=mapping)\n",
    "\n",
    "_, caim_accuracy, _, = scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ff602",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "scorecard.fit(aesthetic_evaluation_X, aesthetic_evaluation_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING',\n",
    "                model_method='ML', \n",
    "                use_sbc=True,\n",
    "                mapping=mapping,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "\n",
    "_, infbins_accuracy, _ = scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f'Execution time: {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9561bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard.plot_accuracy_vs_sparsity(caim_accuracy, num_nonzero_weights, infbins_accuracy, scorecard.nonzero_weights.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827e22a",
   "metadata": {},
   "source": [
    "## wine quality dataset\n",
    "model wine quality, score between 0 and 10, based on physicochemical tests\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/186/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10416a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "wine_quality_data = fetch_ucirepo(id=186) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "wine_quality_X = wine_quality_data.data.features \n",
    "wine_quality_y = wine_quality_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(wine_quality_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(wine_quality_data.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality_y = pd.Series(wine_quality_y['quality'], name='quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_quality_y.hist()\n",
    "plt.xlabel('wine quality')\n",
    "plt.ylabel('drequency')\n",
    "plt.title('distribution of wine quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0078b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = wine_quality_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'Categorical columns: {categorical_columns}')\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    wine_quality_X[col] = wine_quality_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {wine_quality_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1990ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "car_caim_1ook_ml_model, car_caim_1ook_ml_weights = scorecard.fit(wine_quality_X, wine_quality_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bea7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "car_caim_1ook_ml_model, car_caim_1ook_ml_weights = scorecard.fit(wine_quality_X, wine_quality_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K',\n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=18)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "car_caim_1ook_ml_model, car_caim_1ook_ml_weights = scorecard.fit(wine_quality_X, wine_quality_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0091fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237874c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "car_caim_1ook_ml_model, car_caim_1ook_ml_weights = scorecard.fit(wine_quality_X, wine_quality_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970a4264",
   "metadata": {},
   "source": [
    "## car evaluation dataset\n",
    "evaluate car acceptability\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/19/car+evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "car_evaluation_data = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "car_evaluation_X = car_evaluation_data.data.features \n",
    "car_evaluation_y = car_evaluation_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(car_evaluation_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(car_evaluation_data.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c02a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_evaluation_y = pd.Series(car_evaluation_y['class'], name='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_evaluation_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_evaluation_y.hist()\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b749a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get type of each column\n",
    "print(\"types: \", car_evaluation_X.dtypes)\n",
    "\n",
    "# show categorical columns\n",
    "print(\"\\nobject columns: \", car_evaluation_X.select_dtypes(include=['object']).columns)\n",
    "categorical_columns = car_evaluation_X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# show number of unique values in each categorical column\n",
    "print(\"\\nnumber of unique values in each categorical column: \", car_evaluation_X.select_dtypes(include=['object']).nunique())\n",
    "\n",
    "# show values of all categorical columns\n",
    "print(\"\\nvalues of all categorical columns: \", car_evaluation_X.select_dtypes(include=['object']).apply(lambda x: x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = car_evaluation_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"categorical columns: \", categorical_columns)\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    car_evaluation_X.loc[:, col] = car_evaluation_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {car_evaluation_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a07af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "car_caim_1ook_ml_model, car_caim_1ook_ml_weights = scorecard.fit(car_evaluation_X, car_evaluation_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25843418",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "car_infbins_1ook_ml_model, car_infbins_1ook_ml_weights = scorecard.fit(car_evaluation_X, car_evaluation_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K',\n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227efd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "car_caim_diffcoding_ml_model, car_caim_diffcoding_ml_weights = scorecard.fit(car_evaluation_X, car_evaluation_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING',\n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c02b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "car_infbins_diffcoding_ml_model, car_infbins_diffcoding_ml_weights = scorecard.fit(car_evaluation_X, car_evaluation_y, categorical_columns, \n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING',\n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb213c",
   "metadata": {},
   "source": [
    "## abalone\n",
    "predict the age of abalone from physical measurements?\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/1/abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "abalone_data = fetch_ucirepo(id=1) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "abalone_X = abalone_data.data.features \n",
    "abalone_y = abalone_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(abalone_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(abalone_data.variables) \n",
    "\n",
    "abalone_y  = pd.Series(abalone_y ['Rings'], name='Rings')\n",
    "print(abalone_y .value_counts())\n",
    "abalone_y.hist()\n",
    "plt.xlabel('Rings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Rings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = abalone_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"categorical columns: \", categorical_columns)\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    abalone_X.loc[:, col] = abalone_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {abalone_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba27110",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "abalone_caim_1ook_ml_model, abalone_caim_1ook_ml_weights = scorecard.fit(abalone_X, abalone_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90957e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "abalone_infbins_1ook_ml_model, abalone_infbins_1ook_ml_weights = scorecard.fit(abalone_X, abalone_y, categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=10)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "abalone_caim_diffcoding_ml_model, abalone_caim_diffcoding_ml_weights = scorecard.fit(abalone_X, abalone_y,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "abalone_infbins_diffcoding_ml_model, abalone_infbins_diffcoding_ml_weights = scorecard.fit(abalone_X, abalone_y,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a109d8",
   "metadata": {},
   "source": [
    "## balance scale\n",
    "classify each example as having the balance scale tip to the right, tip to the left, or be balanced (from 1 to 5)\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/12/balance+scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbeb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "balance_scale_data = fetch_ucirepo(id=12) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "balance_scale_X = balance_scale_data.data.features \n",
    "balance_scale_y = balance_scale_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(balance_scale_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(balance_scale_data.variables) \n",
    "\n",
    "balance_scale_y  = pd.Series(balance_scale_y['class'], name='class')\n",
    "print(balance_scale_y.value_counts())\n",
    "balance_scale_y.hist()\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65432b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = balance_scale_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"categorical columns: \", categorical_columns)\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    balance_scale_X.loc[:, col] = balance_scale_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {balance_scale_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "balance_scale_caim_1ook_ml_model, balance_scale_caim_1ook_ml_weights = scorecard.fit(balance_scale_X, balance_scale_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545977d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "balance_scale_infbins_1ook_ml_model, balance_scale_infbins_1ook_ml_weights = scorecard.fit(balance_scale_X, balance_scale_y,categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c609fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "balance_scale_caim_diffcoding_ml_model, balance_scale_caim_diffcoding_ml_weights = scorecard.fit(balance_scale_X, balance_scale_y,categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scorecard = Scorecard()\n",
    "balance_scale_infbins_diffcoding_ml_model, balance_scale_infbins_diffcoding_ml_weights = scorecard.fit(balance_scale_X, balance_scale_y,categorical_columns,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7a218",
   "metadata": {},
   "source": [
    "## lenses\n",
    "\n",
    "classes:\n",
    "- 1 : the patient should be fitted with hard contact lenses,\n",
    "- 2 : the patient should be fitted with soft contact lenses,\n",
    "- 3 : the patient should not be fitted with contact lenses.\n",
    "\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/58/lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "lenses_data = fetch_ucirepo(id=58) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "lenses_X = lenses_data.data.features \n",
    "lenses_y = lenses_data.data.targets\n",
    "  \n",
    "# metadata \n",
    "print(lenses_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(lenses_data.variables) \n",
    "\n",
    "lenses_y  = pd.Series(lenses_y['class'], name='class')\n",
    "print(lenses_y.value_counts())\n",
    "lenses_y.hist()\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b495b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = lenses_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"categorical columns: \", categorical_columns)\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    lenses_X.loc[:, col] = lenses_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {lenses_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e293822",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "lenses_caim_1ook_ml_model, lenses_caim_1ook_ml_weights = scorecard.fit(lenses_X, lenses_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "lenses_infbins_1ook_ml_model, lenses_infbins_1ook_ml_weights = scorecard.fit(lenses_X, lenses_y,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ed258",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "lenses_caim_diffcoding_ml_model, lenses_caim_diffcoding_ml_weights = scorecard.fit(lenses_X, lenses_y,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1646d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d16b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "lenses_infbins_diffcoding_ml_model, lenses_infbins_diffcoding_ml_weights = scorecard.fit(lenses_X, lenses_y,\n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1dae0",
   "metadata": {},
   "source": [
    "## student performance\n",
    "predict student performance in secondary education (high school)\n",
    "\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e138cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "student_performance_data = fetch_ucirepo(id=320) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "student_performance_X = student_performance_data.data.features \n",
    "student_performance_y = student_performance_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(student_performance_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(student_performance_data.variables) \n",
    "\n",
    "student_performance_y = pd.Series(student_performance_y['G1'], name='G1')\n",
    "print(student_performance_y.value_counts())\n",
    "student_performance_y.hist()\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c907093",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = student_performance_X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"categorical columns: \", categorical_columns)\n",
    "\n",
    "# encode categorical columns\n",
    "for col in categorical_columns:\n",
    "    student_performance_X.loc[:, col] = student_performance_X[col].astype('category').cat.codes.astype('int')\n",
    "    print(f\"Column {col} encoded as: {student_performance_X[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "student_performance_caim_1ook_ml_model, student_performance_caim_1ook_ml_weights = scorecard.fit(student_performance_X, student_performance_y, categorical_columns, \n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af85e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "student_performance_infbins_1ook_ml_model, student_performance_infbins_1ook_ml_weights = scorecard.fit(student_performance_X, student_performance_y, categorical_columns,   \n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='1_OUT_OF_K', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ec90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "student_performance_caim_diffcoding_ml_model, student_performance_caim_diffcoding_ml_weights = scorecard.fit(student_performance_X, student_performance_y, categorical_columns,\n",
    "                thresholds_method='CAIM',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90014703",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nonzero_weights = scorecard.nonzero_weights.shape[0]\n",
    "print(f'Number of non-zero weights: {num_nonzero_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810b983",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "scorecard = Scorecard()\n",
    "student_performance_infbins_diffcoding_ml_model, student_performance_infbins_diffcoding_ml_weights = scorecard.fit(student_performance_X, student_performance_y, categorical_columns,   \n",
    "                thresholds_method='INF_BINS',\n",
    "                encoding_method='DIFF_CODING', \n",
    "                model_method='ML',\n",
    "                use_sbc=True,\n",
    "                num_nonzero_weights=num_nonzero_weights)\n",
    "scorecard.evaluate()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
