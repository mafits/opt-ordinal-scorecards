{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Differential Scorecards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# discretization\n",
    "from libraries.caimcaim import CAIMD # https://github.com/airysen/caimcaim/blob/master/caimcaim/caimcaim.py\n",
    "\n",
    "# objective function\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# regularization\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **binary data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "synth_X = np.random.rand(100)\n",
    "synth_y = 2*synth_X + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### benchmark datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iris**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "iris_X = pd.DataFrame(iris_data.data)\n",
    "iris_y = pd.DataFrame(iris_data.target)\n",
    "\n",
    "print(\"num observations: \", iris_y.count())\n",
    "print(\"target distribution: \", iris_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adult**: predict whether annual income of an individual exceeds $50K/yr based on census data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "adult_data = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "adult_X = adult_data.data.features \n",
    "adult_y = adult_data.data.targets\n",
    "adult_y.loc[:,'income'] = adult_y['income'].map({'>50K': 1, '<=50K': 0})\n",
    "  \n",
    "# metadata \n",
    "# print(adult_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(adult_data.variables) \n",
    "\n",
    "print(\"num observations: \", adult_y.count())\n",
    "print(\"target distribution: \", adult_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mammo**: discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "mammo_data = fetch_ucirepo(id=161) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "mammo_X = mammo_data.data.features \n",
    "mammo_y = mammo_data.data.targets \n",
    "\n",
    "# drop rows with nulls\n",
    "mammo_combined = pd.concat([mammo_X, mammo_y], axis=1)\n",
    "print(\"num rows with nulls: \", mammo_combined.isnull().sum().sum())\n",
    "mammo_combined = mammo_combined.dropna()\n",
    "mammo_combined = mammo_combined.reset_index(drop=True)\n",
    "mammo_X = mammo_combined.iloc[:, :-1]\n",
    "mammo_y = mammo_combined.iloc[:, -1]\n",
    "\n",
    "\n",
    "# metadata \n",
    "# print(mammo_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(mammo_data.variables) \n",
    "\n",
    "print(\"num observations: \", mammo_y.count())\n",
    "print(\"target distribution: \", mammo_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mushroom**: mushrooms described in terms of physical characteristics; classification: poisonous or edible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "mushroom_data = fetch_ucirepo(id=73) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "mushroom_X = mushroom_data.data.features \n",
    "mushroom_y = mushroom_data.data.targets \n",
    "mushroom_y.loc[:, 'poisonous'] = mushroom_y['poisonous'].map({'p': 1, 'e': 0})\n",
    "  \n",
    "# metadata \n",
    "# print(mushroom_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(mushroom_data.variables) \n",
    "\n",
    "print(\"num observations: \", mushroom_y.count())\n",
    "print(\"target distribution: \", mushroom_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spambase**: classifying Email as Spam or Non-Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "spambase_data = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "spambase_X = spambase_data.data.features \n",
    "spambase_y = spambase_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(spambase_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(spambase_data.variables) \n",
    "\n",
    "print(\"num observations: \", spambase_y.count())\n",
    "print(\"target distribution: \", spambase_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**telemarketing**: set of possible advertisements on Internet pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from file. target is last column\n",
    "telemarketing_data = pd.read_csv('datasets/internet+advertisements/ad.data', dtype=str)\n",
    "telemarketing_X = telemarketing_data.iloc[:, :-1]\n",
    "telemarketing_y = telemarketing_data.iloc[:, -1]\n",
    "\n",
    "# Map target values to binary\n",
    "telemarketing_y = telemarketing_y.map({'nonad.': 0, 'ad.': 1})\n",
    "\n",
    "print(\"num observations: \", telemarketing_y.count())\n",
    "print(\"target distribution: \", telemarketing_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_apnea_data = pd.read_csv('datasets/bdsp_psg_master_20231101.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **discretization thresholds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize using CAIM\n",
    "def discretize_caim_df(data, X, y):\n",
    "    caim = CAIMD()\n",
    "    X_disc_caim = caim.fit_transform(X, y) # fit() and transform()\n",
    "    \n",
    "    print(\"\\nCut-off points: \", caim.split_scheme)\n",
    "    print(\"Number of bins: \", end=\"\")\n",
    "    for i, (key, value) in enumerate(caim.split_scheme.items()):\n",
    "        if i == len(caim.split_scheme) - 1:\n",
    "            print(f\" {key}: {len(value)+1}\", end=\"\")\n",
    "        else:\n",
    "            print(f\" {key}: {len(value)+1}\", end=\",\")\n",
    "    print()\n",
    "    \n",
    "    X_disc_caim = pd.DataFrame(X_disc_caim, columns=X.columns).astype(int) # convert to pandas dataframe and int\n",
    "        \n",
    "    return X_disc_caim\n",
    "\n",
    "def discretize_caim(X, cols, y):\n",
    "    caim = CAIMD()\n",
    "    X_disc_caim = caim.fit_transform(X, y) # fit() and transform()\n",
    "    # get thresholds from caim.split_scheme (dict with column index : thresholds)\n",
    "    # transform all values to floats\n",
    "    # and keys with column indexes to column names\n",
    "    thresholds = {cols[i]: [float(val) for val in value] for i, (key, value) in enumerate(caim.split_scheme.items())}\n",
    "    return thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammo_thresholds_caim = discretize_caim(mammo_X, mammo_X.columns, mammo_y)\n",
    "print(\"thresholds \", mammo_thresholds_caim)\n",
    "\n",
    "print(\"num of bins: \")\n",
    "for i, (key, value) in enumerate(mammo_thresholds_caim.items()):\n",
    "        print(f\"  {key}: {len(value)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infinitesimal bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize using infinitesimal bins:\n",
    "# thresholds are the points in between 2 consecutive values in the sorted list\n",
    "\n",
    "def discretize_infbins(X, cols):\n",
    "    infbins_thresholds = {}\n",
    "    for col in cols:\n",
    "        # sort unique values\n",
    "        sorted_col = np.unique(X[col])\n",
    "        # get thresholds\n",
    "        thresholds = (sorted_col[:-1] + sorted_col[1:]) / 2\n",
    "        infbins_thresholds[col] = thresholds.tolist()\n",
    "\n",
    "    return infbins_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammo_thresholds_infbins = discretize_infbins(mammo_X, mammo_X.columns)\n",
    "print(\"thresholds \", mammo_thresholds_infbins)\n",
    "print(\"num of bins: \")\n",
    "for i, (key, value) in enumerate(mammo_thresholds_infbins.items()):\n",
    "        print(f\"  {key}: {len(value)+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discretized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num of columns in the new df = (num thresholds + 1) * num features = num bins * num features\n",
    "\n",
    "2 methods\n",
    "- 1 out of k: 1 if the value is in the bin, 0 otherwise\n",
    "- differential coding: 1 from bin 1 until bin where the value is in, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins(thresholds, values):\n",
    "    bins = np.digitize(values, thresholds)\n",
    "    return bins\n",
    "    # list of bin number for each row\n",
    "\n",
    "def disc_1_out_of_k(X, cols, thresholds):\n",
    "    disc_df = []\n",
    "    for col in cols:\n",
    "        bins = get_bins(thresholds[col], X[col]) # gets bin number of each row\n",
    "        bins_df = pd.get_dummies(bins, prefix=f'feat{col}-bin').astype(int) # one hot encoding\n",
    "        bins_df = bins_df.drop(columns=f'feat{col}-bin_0')\n",
    "        disc_df.append(bins_df)\n",
    "    return pd.concat(disc_df, axis=1)\n",
    "\n",
    "def disc_diff_coding(X, cols, thresholds):\n",
    "    bin_dfs = []\n",
    "    for col in cols:\n",
    "        bins = get_bins(thresholds[col], X[col]) # gets bin number of each row\n",
    "        num_bins = len(thresholds[col]) + 1\n",
    "        bin_df = pd.DataFrame(0, index=X.index, columns=[f'feat{col}-bin_{i}' for i in range(1, num_bins)])\n",
    "        for i in range(1, num_bins):\n",
    "            bin_df[f'feat{col}-bin_{i}'] = (bins >= i).astype(int)\n",
    "        bin_dfs.append(bin_df)\n",
    "    return pd.concat(bin_dfs, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammo_X_disc_infbins_1outofk = disc_1_out_of_k(mammo_X, mammo_X.columns, mammo_thresholds_infbins)\n",
    "mammo_X_disc_infbins_1outofk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mammo_X_disc_infbins_diffcod = disc_diff_coding(mammo_X, mammo_X.columns, mammo_thresholds_infbins)\n",
    "mammo_X_disc_infbins_diffcod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Least Squares (RSS)\n",
    "- Maximum Likelihood (GLM with binomial response and logit link function)\n",
    "- margin maximization (linear SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS\n",
    "# call least_squares(fun, x0)\n",
    "\n",
    "# maximum likelihood\n",
    "def max_lik(parameters):\n",
    "    m = parameters[0]\n",
    "    b = parameters[1]\n",
    "    sigma = parameters[2]\n",
    "    for i in np.arange(0, len(x)):\n",
    "        y_exp = m * x + b\n",
    "    L = (len(x)/2 * np.log(2 * np.pi) + len(x)/2 * np.log(sigma ** 2) + 1 /\n",
    "         (2 * sigma ** 2) * sum((y - y_exp) ** 2))\n",
    "    return L\n",
    "\n",
    "x = 1\n",
    "y = 2\n",
    "lik_model = minimize(max_lik, 0, method='L-BFGS-B')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.7).fit(iris_X, iris_y)\n",
    "print(f\"Ridge Regression-Training set score: {ridge.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Ridge Regression-Test set score: {ridge.score(iris_X, iris_y):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01).fit(iris_X, iris_y)\n",
    "print(f\"Lasso Regression-Training set score: {lasso.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Lasso Regression-Test set score: {lasso.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Number of features Lasso: {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01).fit(iris_X, iris_y)\n",
    "print(f\"Elastic Net-Training set score: {elastic_net.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Elastic Net-Test set score: {elastic_net.score(iris_X, iris_y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ordinal data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_data = pd.read_csv('datasets/aesthetic_evaluation_data.csv')\n",
    "aesthetic_evaluation_data = aesthetic_evaluation_data.drop(columns=['Image Filename','Author','Objective Evaluation'])\n",
    "aesthetic_evaluation_X = aesthetic_evaluation_data.drop(columns='Subjective Evaluation')\n",
    "aesthetic_evaluation_y = aesthetic_evaluation_data['Subjective Evaluation']\n",
    "\n",
    "aesthetic_evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aesthetic_evaluation_data[['sX2L Value','sX2a Value','sX2b Value','sX2Lab Value','sEMDL Value','sEMDa Value','sEMDb Value','sEMDLab Value']]\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.hist()\n",
    "plt.xlabel('Subjective Evaluation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Subjective Evaluation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
