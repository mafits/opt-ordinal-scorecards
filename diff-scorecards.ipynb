{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Differential Scorecards**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# discretization\n",
    "from libraries.caimcaim import CAIMD # https://github.com/airysen/caimcaim/blob/master/caimcaim/caimcaim.py\n",
    "\n",
    "# objective function\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# regularization\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **binary data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "synth_X = np.random.rand(100)\n",
    "synth_y = 2*synth_X + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### benchmark datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iris**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "iris_X = pd.DataFrame(iris_data.data)\n",
    "iris_y = pd.DataFrame(iris_data.target)\n",
    "\n",
    "print(\"num observations: \", iris_y.count())\n",
    "print(\"target distribution: \", iris_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adult**: predict whether annual income of an individual exceeds $50K/yr based on census data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "adult_data = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "adult_X = adult_data.data.features \n",
    "adult_y = adult_data.data.targets\n",
    "adult_y['income'] = adult_y['income'].map({'>50K': 1, '<=50K': 0})\n",
    "  \n",
    "# metadata \n",
    "# print(adult_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(adult_data.variables) \n",
    "\n",
    "print(\"num observations: \", adult_y.count())\n",
    "print(\"target distribution: \", adult_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mammo**: discrimination of benign and malignant mammographic masses based on BI-RADS attributes and the patient's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "mammo_data = fetch_ucirepo(id=161) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "mammo_X = mammo_data.data.features \n",
    "mammo_y = mammo_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(mammo_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(mammo_data.variables) \n",
    "\n",
    "\n",
    "print(\"num observations: \", mammo_y.count())\n",
    "print(\"target distribution: \", mammo_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mushroom**: mushrooms described in terms of physical characteristics; classification: poisonous or edible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "mushroom_data = fetch_ucirepo(id=73) \n",
    "\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "mushroom_X = mushroom_data.data.features \n",
    "mushroom_y = mushroom_data.data.targets \n",
    "mushroom_y['poisonous'] = mushroom_y['poisonous'].map({'p': 1, 'e': 0})\n",
    "  \n",
    "# metadata \n",
    "# print(mushroom_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(mushroom_data.variables) \n",
    "\n",
    "print(\"num observations: \", mushroom_y.count())\n",
    "print(\"target distribution: \", mushroom_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spambase**: classifying Email as Spam or Non-Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "spambase_data = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "spambase_X = spambase_data.data.features \n",
    "spambase_y = spambase_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "# print(spambase_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "# print(spambase_data.variables) \n",
    "\n",
    "print(\"num observations: \", spambase_y.count())\n",
    "print(\"target distribution: \", spambase_y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**telemarketing**: set of possible advertisements on Internet pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from file. target is last column\n",
    "telemarketing_data = pd.read_csv('datasets/internet+advertisements/ad.data')\n",
    "telemarketing_X = telemarketing_data.iloc[:, :-1]\n",
    "telemarketing_y = telemarketing_data.iloc[:, -1]\n",
    "\n",
    "#telemarketing_y['ad'] = telemarketing_y['ad'].map({'nonad.': 0, 'ad.': 1})\n",
    "\n",
    "\n",
    "print(\"num observations: \", telemarketing_y.count())\n",
    "print(\"target distribution: \", telemarketing_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_apnea_data = pd.read_csv('datasets/bdsp_psg_master_20231101.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **discretization thresholds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize using CAIM\n",
    "def discretize_caim_df(data, X, y):\n",
    "    caim = CAIMD()\n",
    "    X_disc_caim = caim.fit_transform(X, y) # fit() and transform()\n",
    "    \n",
    "    print(\"\\nCut-off points: \", caim.split_scheme)\n",
    "    print(\"Number of bins: \", end=\"\")\n",
    "    for i, (key, value) in enumerate(caim.split_scheme.items()):\n",
    "        if i == len(caim.split_scheme) - 1:\n",
    "            print(f\" {key}: {len(value)+1}\", end=\"\")\n",
    "        else:\n",
    "            print(f\" {key}: {len(value)+1}\", end=\",\")\n",
    "    print()\n",
    "    \n",
    "    X_disc_caim = pd.DataFrame(X_disc_caim, columns=data.feature_names).astype(int) # convert to pandas dataframe and int\n",
    "        \n",
    "    return X_disc_caim\n",
    "\n",
    "def discretize_caim(data, X, y):\n",
    "    caim = CAIMD()\n",
    "    X_disc_caim = caim.fit_transform(X, y) # fit() and transform()\n",
    "    thresholds = caim.split_scheme\n",
    "    return thresholds\n",
    "\n",
    "''' prints of fit() method:\n",
    "Categorical list_of_(indicies)_categorical_features\n",
    "# feature_index  GLOBAL CAIM  best_caim_value \n",
    "\n",
    "in the returning dataframe:\n",
    "    - columns represent the original features\n",
    "    - rows represent each instance\n",
    "    - values are the bin number each instance belongs to (starting from 0) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_thresholds_caim = discretize_caim(iris_data, iris_X, iris_y)\n",
    "print(iris_thresholds_caim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infinitesimal bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize using infinitesimal bins:\n",
    "# thresholds are the points in between 2 consecutive values in the sorted list\n",
    "\n",
    "def discretize_infbins(X):\n",
    "    infbins_thresholds = {}\n",
    "    for col in range(X.shape[1]):\n",
    "        # sort \n",
    "        sorted_col = np.unique(np.sort(X.transpose()[col]))\n",
    "        # get thresholds\n",
    "        thresholds = []\n",
    "        for i in range(len(sorted_col)-1):\n",
    "            thresholds.append((sorted_col[i] + sorted_col[i+1])/2)\n",
    "        infbins_thresholds[col] = thresholds\n",
    "\n",
    "    return infbins_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_thresholds_infbins = discretize_infbins(iris_X)\n",
    "print(iris_thresholds_infbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discretized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colunas novas = (num intervalos + 1)*num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with columns = (num of bins + 1) * num of features\n",
    "# (filled with 0)\n",
    "\n",
    "def get_discretized_cols(X, thresholds):\n",
    "    col_names = []\n",
    "    for col in range(X.shape[1]):\n",
    "        for bin in range(len(thresholds[col]) + 1):\n",
    "            new_col_name = 'feat' + str(col) + '-bin' + str(bin)\n",
    "            col_names.append(new_col_name)\n",
    "    \n",
    "    X_disc = pd.DataFrame(columns=col_names)\n",
    "    for i in range(len(X)):\n",
    "        X_disc.loc[i] = 0\n",
    "    \n",
    "    return X_disc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_disc = get_discretized_cols(iris_X, iris_thresholds_infbins)\n",
    "iris_X_disc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 out of k: preencher com bools (de pertencer ao intervalo)\n",
    "- differential coding: 1 atÃ© ao bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given thresholds of a feature and a value\n",
    "# return index of bin the values belongs to\n",
    "def get_bin(thresholds, value):\n",
    "    if(value < thresholds[0]):\n",
    "        return 0\n",
    "    if(value >= thresholds[len(thresholds)-1]):\n",
    "        return len(thresholds)\n",
    "    for i in range(len(thresholds)-1):\n",
    "        if(value >= thresholds[i] and value < thresholds[i+1]):\n",
    "            return i\n",
    "\n",
    "\n",
    "# 1 out of k\n",
    "def disc_1_out_of_k(X, thresholds):\n",
    "    new_df = get_discretized_cols(X, thresholds)\n",
    "    # iterate through features\n",
    "    for instance in range(X.shape[0]):\n",
    "        for col in range(X.shape[1]):\n",
    "            bin = get_bin(thresholds[col], X[instance][col])\n",
    "            new_df['feat' + str(col) + '-bin' + str(bin)][instance] = 1\n",
    "    return new_df\n",
    "\n",
    "# 1 out of k\n",
    "# but take out 1st bin\n",
    "def disc_1_out_of_k_V2(X, thresholds):\n",
    "    new_df = get_discretized_cols(X, thresholds)\n",
    "    col_names = []\n",
    "    # delete columns of 1st bin for each feature\n",
    "    for col in range(X.shape[1]):\n",
    "        col_names.append('feat' + str(col) + '-bin' + str(0))\n",
    "    new_df = new_df.drop(columns=col_names)\n",
    "    \n",
    "    # go through all instances\n",
    "    for instance in range(X.shape[0]):\n",
    "        # go through each feature\n",
    "        for col in range(X.shape[1]):\n",
    "            bin = get_bin(thresholds[col], X[instance][col])\n",
    "            if(bin == 0): continue\n",
    "            new_df['feat' + str(col) + '-bin' + str(bin)][instance] = 1\n",
    "    return new_df\n",
    "\n",
    "\n",
    "# differential coding\n",
    "def disc_diff_coding(X, thresholds):\n",
    "    new_df = get_discretized_cols(X, thresholds)\n",
    "    # iterate through features\n",
    "    for instance in range(X.shape[0]):\n",
    "        for col in range(X.shape[1]):\n",
    "            bin = get_bin(thresholds[col], X[instance][col])\n",
    "            for i in range(0, bin+1):\n",
    "                new_df['feat' + str(col) + '-bin' + str(i)][instance] = 1\n",
    "    return new_df\n",
    "            \n",
    "def disc_diff_coding_V2(X, thresholds):\n",
    "    new_df = get_discretized_cols(X, thresholds)\n",
    "    \n",
    "    col_names = []\n",
    "    # delete columns of 1st bin for each feature\n",
    "    for col in range(X.shape[1]):\n",
    "        col_names.append('feat' + str(col) + '-bin' + str(0))\n",
    "    new_df = new_df.drop(columns=col_names)\n",
    "    \n",
    "    # iterate through features\n",
    "    for instance in range(X.shape[0]):\n",
    "        for col in range(X.shape[1]):\n",
    "            bin = get_bin(thresholds[col], X[instance][col])\n",
    "            if(bin == 0): continue\n",
    "            for i in range(1, bin+1):\n",
    "                new_df['feat' + str(col) + '-bin' + str(i)][instance] = 1\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_disc_infbins_1outofk = disc_1_out_of_k(iris_X, iris_thresholds_infbins)\n",
    "iris_X_disc_infbins_1outofk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_disc_infbins_1outofk_V2 = disc_1_out_of_k_V2(iris_X, iris_thresholds_infbins)\n",
    "iris_X_disc_infbins_1outofk_V2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_disc_infbins_diff_coding = disc_diff_coding(iris_X, iris_thresholds_infbins)\n",
    "iris_X_disc_infbins_diff_coding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X_disc_infbins_diff_coding_V2 = disc_diff_coding_V2(iris_X, iris_thresholds_infbins)\n",
    "iris_X_disc_infbins_diff_coding_V2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Least Squares (RSS)\n",
    "- Maximum Likelihood (GLM with binomial response and logit link function)\n",
    "- margin maximization (linear SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS\n",
    "# call least_squares(fun, x0)\n",
    "\n",
    "# maximum likelihood\n",
    "def max_lik(parameters):\n",
    "    m = parameters[0]\n",
    "    b = parameters[1]\n",
    "    sigma = parameters[2]\n",
    "    for i in np.arange(0, len(x)):\n",
    "        y_exp = m * x + b\n",
    "    L = (len(x)/2 * np.log(2 * np.pi) + len(x)/2 * np.log(sigma ** 2) + 1 /\n",
    "         (2 * sigma ** 2) * sum((y - y_exp) ** 2))\n",
    "    return L\n",
    "\n",
    "x = 1\n",
    "y = 2\n",
    "lik_model = minimize(max_lik, 0, method='L-BFGS-B')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.7).fit(iris_X, iris_y)\n",
    "print(f\"Ridge Regression-Training set score: {ridge.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Ridge Regression-Test set score: {ridge.score(iris_X, iris_y):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.01).fit(iris_X, iris_y)\n",
    "print(f\"Lasso Regression-Training set score: {lasso.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Lasso Regression-Test set score: {lasso.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Number of features Lasso: {sum(lasso.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.01).fit(iris_X, iris_y)\n",
    "print(f\"Elastic Net-Training set score: {elastic_net.score(iris_X, iris_y):.2f}\")\n",
    "print(f\"Elastic Net-Test set score: {elastic_net.score(iris_X, iris_y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ordinal data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_data = pd.read_csv('datasets/aesthetic_evaluation_data.csv')\n",
    "aesthetic_evaluation_data = aesthetic_evaluation_data.drop(columns=['Image Filename','Author','Objective Evaluation'])\n",
    "aesthetic_evaluation_X = aesthetic_evaluation_data.drop(columns='Subjective Evaluation')\n",
    "aesthetic_evaluation_y = aesthetic_evaluation_data['Subjective Evaluation']\n",
    "\n",
    "aesthetic_evaluation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = aesthetic_evaluation_data[['sX2L Value','sX2a Value','sX2b Value','sX2Lab Value','sEMDL Value','sEMDa Value','sEMDb Value','sEMDLab Value']]\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetic_evaluation_y.hist()\n",
    "plt.xlabel('Subjective Evaluation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Subjective Evaluation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
